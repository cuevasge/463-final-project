---
title: "Final Project - Biodiversity in the Great Barrier Reef"
author: "Gabriela Cuevas & Max Baumstark"
date: "2025-11-10"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

In this report, we will investigate how environmental factors such as ocean temperature, pH level, bleaching level, latitude, and longitude impact marine biodiversity. Our data is assembled from various climate organization research (NOAA, GODAP, OBIS) assembled for the purpose of finding climate trends and creating future predictions. We will perform model diagnostics and multiple regression to determine which factors are most significant.

# Data

### Data Cleaning and Filtering
```{r, warning=FALSE, message=FALSE}
rm(list = ls())

library(readxl)
library(dplyr)
library(janitor)
library(tidyverse)
library(gridExtra)
library(zoo)
library(lmtest)
library(nortest)
library(car)
library(ggplot2)
library(caret)

setwd("/Users/gabrielacuevas/Desktop/STA 463/FinalProject")
dat = read.csv("ocean.csv",header=T)

head(dat)
dim(dat)
```

Before cleaning our data, we have exactly 500 observations observed over many different locations across the globe.

To better understand our dataset, we want to specifically look at the Great Barrier Reef.

Also, we are going to rename the SST column to temperature, eliminate the marine heatwave predictor, and eliminate any null observations.

We also want to mention that latitude and longitude are constrained to the general region of the GBR, so they are discrete variables.

```{r}
clean_dat <- dat %>%
  select (-Marine.Heatwave) %>%  
   rename(
     temperature = SST,
     pH = pH.Level,
     species = Species.Observed,
     bleachLevel = Bleaching.Severity
   )
 
# convert species to integer
clean_dat$species <- as.integer(clean_dat$species)
# filter for Great Barrier Reef
GBR_dat <- clean_dat %>%
   filter(Location == "Great Barrier Reef")


head(GBR_dat)
dim(GBR_dat)
```

After cleaning the data, there are 87 observations pertaining to our geographic region of interest, The Great Barrier Reef.

Now, we have to create dummy variables in order to indicate the severity of the bleaching level in the Great Barrier Reef.

### Creating Dummy for Bleach Level

```{r}
GBR_dat$highBleach <- ifelse(GBR_dat$bleachLevel == "High", 1, 0)
GBR_dat$mediumBleach <- ifelse(GBR_dat$bleachLevel == "Medium", 1, 0)
GBR_dat$lowBleach <- ifelse(GBR_dat$bleachLevel == "Low", 1, 0)
GBR_dat <- GBR_dat %>%
  select (-bleachLevel)

head(GBR_dat)
```

After the data has been cleaned, we are able to move on to the methods of our project.

# Methods

## Fitting a Multiple Regression Model

```{r}
lm_ocean_full <- lm(species ~ temperature + pH + Latitude + Longitude + highBleach + mediumBleach + lowBleach, data = GBR_dat)
summary(lm_ocean_full)
```

Our initial summary indicates that temperature is the only significant predictor (as it is the only predictor value below any reasonable significance level). The other predictor that has a relatively low p-value is longitude, but we will take a closer look into the significant predictors in the future.

Multiple R-Squared: 0.4895

Adjusted R-Squared: 0.0443

### *Full Model Coefficients:*

Intercept = -5570.5744

Temperature = -9.7432

pH = -10.1908

Latitude = 16.3202

Longitude = 43.0045

highBleach = 0.2286

mediumBleach = -2.6331

lowBleach = -2.0113

## *Observations:*

The R-Squared values suggest that there is a moderate correlation between the predictors and and the number of species in the GBR. There is also a difference of about 0.045 between the R-Squared and the Adjusted R-Squared, suggesting a strong penalty induced by including so many predictors.

The intercept coefficient is not meaningful. There is no case in which there will be a negative number of species in the the GBR.

Next, let's make sure no model assumptions are being violated, and make any transformations if needed.

## Assumptions & Diagnostics

First, we are going to make a visual representation of the predicted vs. observed values.

```{r}
GBR_dat$fit_full <- fitted(lm_ocean_full)

p1 <- ggplot(GBR_dat, aes(x = species, y = fit_full)) +
geom_point(color = "steelblue") +
geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Full Model: Fitted vs Actual",
x = "Actual num of species",
y = "Fitted num of species"
) +
theme_minimal()
p1
```

There aren't any glaring obscurities when it comes to observed values deviating from the predicted values, so we can move into checking individual assumptions.


```{r}
par(mfrow = c(2, 2))
plot(lm_ocean_full)
```

#### *Linearity:*

The linearity assumption does not appear to be violated as the vertical scatter of points in the residuals vs. fitted plot seems to be random scattered around zero.

#### *Independence of Errors:*

Each observation was collected on a different date and represents a separate measurement from an independent subject/time point, making it unlikely that the measurement from one day influenced the next.

#### *Constant Variance:*

On the Scale-Location plot, we can see that on the tails, there is moderate variation from the horizontal line in the center, but nothing too serious. We will keep this in mind when completing the Breusch-Pagan test.

```{r}
bptest(lm_ocean_full)
```

p-value: 0.6933

Since the p-value is greater than any reasonable significance level, we can conclude that the constant variance assumption remains intact.

#### *Normality:*

Looking at the Q-Q Plot above, there is slight variation at the tails of the plot, and these observations are designated as possible influential points. This is something to keep in mind when we check for influential points later on. Next, we can conduct a Shapiro-Wilk test for normality.

```{r}
shapiro.test(residuals(lm_ocean_full))
```

The Shapiro-Wilk test indicates that the residuals deviate from normality. We can also perform the Anderson-Darling test for Normality.

```{r}
ad.test(lm_ocean_full$residuals)
```

The Anderson-Darling normality test suggests that the normality assumption is not being violated. Since we have conflicting tests, we should check for influential points now so we can determine if these are what is causing the lack of normality.

#### *Removing Outliers?*

Residuals vs Leverage
```{r}
plot(lm_ocean_full, which = 4)  
plot(lm_ocean_full, which = 6)
```

The Cook's Distance plot suggests that observations 28, 62, and 66 are highly influential points.

```{r}
influencePlot(lm_ocean_full)
```

The Cook's Distance bubble plot suggests that observations 26, 28, 42, 61, and 62

We can look into the hat values of every value.

```{r}
lev <- hatvalues(lm_ocean_full)
lev
lev[lev > (2*(7+1)/87)]
```

The hat value test suggests that no values differ too greatly as influential points.

Studentized Residuals will be the next thing we to look into.

```{r}
r <- rstudent(lm_ocean_full)
r
```

The observations with the largest studentized residual values: 8, 28, 42, 62, and 66.

All of these observations have studentized residual values above 2, flagging them as possible outliers.

After running these tests, there are no points that are suggested as outliers throughout each test, and no points that show extreme values when it comes to individual test results. Therefore, removal of any observation is not necessary in this case, but it will be a good idea to look into different transformations.

So, our influential points assumption holds, and we can look back to our normality assumption.

#### *Normality re-check*

Since we have verified our influential observation assumption is not violated, we can determine that the normality assumption is also in check. After some investigations, the BP test returning significant is likely due to the moderately influential points discussed above. However, with large sample sizes, this test often comes back as significant if there are even slightly influential predictors.

The more important test for normality is the Normal Q-Q Plot, which suggests that the normality assumption is met. The next assumption to be checked is the existence of multicollinearity.

#### *Multicollinearity*

```{r}
vif(lm_ocean_full)
```

All of our predictors have a VIF value below 1.5, which suggests no existence of multicollinearity.

#### *No Important Predictors Omitted:*

The predictor that we removed was Marine Heatwave. We removed this due to a lack of observations that were indicated as being during a marine heatwave, and to avoid multicollinearity with the temperature predictor.

#### *Possible Lack-of-Fit:*

The lack-of-fit assumption was evaluated using the Residuals vs. Fitted plot. The residuals showed no systematic patterns or curvature, indicating that a linear model provides an adequate description of the relationships in the data.

Since the dataset does not contain replicated predictor values, a formal lack-of-fit test could not be performed. Overall, there is no visual evidence of lack of fit, and the linear model form appears appropriate.

#### *What if we removed the influential observations?*

While we decided not to remove the influential points in this project, it is still a good idea to get an idea of what the rest of the data looks like without the outliers. Below, we have removed the five most influential points, and completed an analysis on what was left.

```{r}
influential_indices <- c(28, 42, 61, 62, 66)
GBR_filtered <- GBR_dat[-influential_indices, ]
lm_ocean_filtered <- lm(species ~ temperature + pH + Latitude + Longitude + highBleach + mediumBleach + lowBleach, data = GBR_filtered)
summary(lm_ocean_full)
summary(lm_ocean_filtered)
```

When the influential points are removed from the model, longitude is much more significant. This suggests that the further south one travels down the GBR, the greater the number of species will be.

Also, the predictors explain much more of the data as the Adjusted R-Squared bumps up from 0.44 to 0.55. This is a significant increase in the performance of the model.

One my wonder, if the model fits better, why would we not simply remove the data points?

In regression, we want to avoid 'choosing' what data to include in models as much as possible, otherwise we are not providing a true representative of the population we are trying to model. Observations should only be removed if they are extreme, and we have determined that these observations are not extreme.

```{r}
coef_full <- coef(lm_ocean_full)
coef_filtered <- coef(lm_ocean_filtered)
comparison <- data.frame(Full_Model = coef_full, Filtered_Model = coef_filtered)
print(comparison)
```


# Model Selection

*Box-Cox Plot*

Since a few assumptions/diagnostics were not entirely convincing, we should look at a box-cox plot to see if a transformation is necessary

```{r}
boxCox(lm_ocean_full)
```

The box-cox plot shows that a square root transformation would be beneficial to this dataset.

```{r}
sqrt_ocean <- lm(sqrt(species)  ~ temperature + pH + Latitude + Longitude + highBleach + mediumBleach + lowBleach, data = GBR_dat)
summary(sqrt_ocean)
```


```{r}
boxCox(sqrt_ocean)
```

The transformed data's lambda value is approximately one, which is exactly what we want to see. Let's compare assumptions/diagnostics of the square rooted data compared to the original data.

### Visualize all predictors

```{r}
avPlots(lm_ocean_full)
avPlots(sqrt_ocean)
```

The added variable plots are almost identical between the two models, so any conclusions can be shared between both models.

From these added variable plots, we can see that the only predictor besides temperature that has a notable relationship with the number of species is longitude. In that plot, there is a slight positive correlation between number of species and longitude. This tells us that there is higher biodiversity in the northern parts of the Great Barrier Reef. This graph also highlights 62, 42, and 32 as outliers, which matches up with our cook's distance plot.

```{r}
bptest(lm_ocean_full)
bptest(sqrt_ocean)

shapiro.test(residuals(lm_ocean_full))
shapiro.test(residuals(sqrt_ocean))

ad.test(lm_ocean_full$residuals)
ad.test(sqrt_ocean$residuals)

vif(lm_ocean_full)
vif(sqrt_ocean)
```

All of the test results from the Breusch-Pagan test, Shapiro-Wilk test, Anderson-Darling test, and vif values do not vary enough between models to designate one over another.

```{r}
influencePlot(lm_ocean_full)
influencePlot(sqrt_ocean)
```

Again, there are very minimal differences between the studentized residuals, hat values, and cook's distance values, so we can keep the same conclusions we drew for the original model.

### Original Data Vs. Transformed Data Assumptions

```{r}
par(mfrow = c(2, 2))
plot(lm_ocean_full)

plot(sqrt_ocean)
```

The diagnostic plots look almost identical, so these can not be used to distinguish between the models.

### Compare AIC and Adjusted R²

One more thing that that can be checked when it comes to comparing the original model compared to the transformed model is the AIC and BIC values of the
```{r}
data.frame(
Model = c("sqrt", "Full"),
Adj_R2 = c(summary(sqrt_ocean)$adj.r.squared, summary(lm_ocean_full)$adj.r.squared),
AIC = c(AIC(sqrt_ocean), AIC(lm_ocean_full)),
BIC = c(BIC(sqrt_ocean), BIC(lm_ocean_full))
)
```

Here, we can see that all three of the measurements of goodness of fit indicate that the model fits the transformed data much better.

The AIC and BIC values are the biggest indicator as there is a greater than 3x increase in both AIC and BIC in the full model compared to the transformed model.

For these reasons, we can move forward with the conclusion that the transformed model fits our data better than the original model.

### Model Selection
```{r}
# Null model (only intercept)
null_model <- lm(species ~ 1, data = GBR_dat)

# Forward selection
forward_model <- step(null_model,
                      scope = list(lower = null_model, upper = sqrt_ocean),
                      direction = "forward")
summary(forward_model)

# Backward elimination
backward_model <- step(sqrt_ocean, direction = "backward")
summary(backward_model)

# Stepwise selection (both directions)
stepwise_model <- step(null_model,
                       scope = list(lower = null_model, upper = sqrt_ocean),
                       direction = "both")
summary(stepwise_model)
```

All three selection methods choose a method with two predictors:

***Temperature & Longitude***

However, the summary of this model indicates longitude is not a significant predictor. Therefore, further exploration is needed to determine whether the best model includes longitude or not.

```{r}
lm_ocean_sqrt_reduced <- lm(sqrt(species) ~ temperature + Longitude, data = GBR_dat)
lm_ocean_sqrt_temp <- lm(sqrt(species) ~ temperature, data = GBR_dat)

summary(lm_ocean_sqrt_reduced)
summary(lm_ocean_sqrt_temp)

AIC(lm_ocean_sqrt_reduced)
AIC(lm_ocean_sqrt_temp)

BIC(lm_ocean_sqrt_reduced)
BIC(lm_ocean_sqrt_temp)

```

Model Statistic Comparisions:

The adjusted r-squared values are almost identical between the two models (0.4844 and 0.4733) suggesting that the simpler model is the one we should go with.

The F-statistic for the simpler model is almost 2x greater than the F-statistic of the model that includes longitude (41.4  and 78.29). This suggests that the simpler model explains more of the variance compared to the random noise.

There is not a difference in AIC or BIC greater than two between the models, meaning that AIC and BIC both suggest going with the simpler model.

### Partial F-Test
```{r}
anova(lm_ocean_sqrt_reduced, lm_ocean_sqrt_temp)
```

Our partial F-Test indicates that we lack sufficient evidence to reject the null hypothesis we have a p-value greater than 0.05. This test indicates that there is not a significant difference between the models, and that the simpler model should be selected to avoid over-fitting.

### Final Model Selection

Taking all these statistics into consideration, the decision to go with the simple model seems very self-explanatory. We have decided to go against what the model selection functions said to keep the model as simple as possible, while still keeping as much explanation of variability as we can.

So, our final model is made up of only one predictor with a square-root transformation, temperature to predict the number of species in a given area.

# Results

### Interpretation of the summary output

```{r}
final_model <- lm(sqrt(species) ~ temperature, data = GBR_dat)
summary(final_model)
```

Intercept: 23.73932 - When the temperature is 0 degrees Celsius, the expected biodiversity of a region is 395.419. This intercept by itself does not mean anything because it is outside the scope of our data. The range of temperature values we observed in our data set was from 26.2 to 32.34. Also the range of biodiversity is from 75 to 162.

temperature: -0.44636 - For each increase in the square root of the temperature (degrees celsius), the expected biodiversity will decrease by -0.44636.

R-Squared: 0.4794 - about 48% of the variation in our data can be described by the temperature (degrees celsius) at that location.

F-Statistic: 78.29 & p-value: 1.097e-13 - These values are significant, meaning that we can reject the null hypothesis that the predictors do not fit the data.

### Further Insights

## Plot Temp against Number of Species
```{r}
temp <- ggplot(GBR_dat, aes(x = temperature, y = species)) +
  geom_point(size = 3) +  # dots
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # linear regression line
  labs(
    title = "Number of Species by Temperature for the Great Barrier Reef",
    x = "Temperature",
    y = "Number of Species"
  ) +
  ylim(0, 170) +
  scale_x_continuous(breaks = seq(min(GBR_dat$temperature), max(GBR_dat$temperature), by = 1))+
  theme_minimal()
temp
```


- As the temperature increases, the expected biodiversity decreases.
- This plot is visualized on our original scale.

 - Our model predicts that at 41.2 degrees celsius, there will be zero biodiversity. This makes sense as the larges observed value of temperature was 32.34 degrees and the lowest observed biodiversity observed was 75, not very close to 0.

### Cross - Validation
```{r}
train_control <- trainControl(
  method = "cv",
  number = 5,
  savePredictions = "final"
)

# Train the model using 5-fold CV
cv_final <- train(
  species ~ temperature,
  data = GBR_dat,
  method = "lm",
  trControl = train_control,
)

cv_final
```

RMSE: 14.06379 - This value reflects the moderate strength predictability our model offers. On average predictions of biodiversity will be off by about 14.

R-Squared: 0.435 - This is very similar to our R-squared we gathered from our observed values, meaning our data is consistent at predicting data from outside the source we fitted from. This is due to us not deciding to overfit the model.

MAE: 11.31606 - This value echoes the same conclusion from RMSE, that our model is not the strongest, but the errors are consistent, and not driven by extreme points.

# Discussion and Story

From our study, a simple linear regression model with temperature and longitude would represent our data in the same way as our full model. Temperature was the only significant predictor of marine biodiversity. Sea surface temperature increases as a result of greenhouse gases such as carbon dioxide and methane in the atmosphere. We can use studies like these to predict how climate mitigation can slow down biodiversity loss. Current research has determined that if we are able to keep global temperatures below 2 degrees Celsius until 2100, we can slow dramatic oceanic environmental changes enough for coral reefs to recover and maintain their biodiversity levels. Global temperatures have increased by about 1 degree C in the past 20 years, and our current global temperature is 1.33 degrees C above pre-industrial temperatures. This means we must take significant measures to slow global temperature increase through reducing carbon emissions, fossil fuel usage, and preventing deforestation. In future studies, we would like to take a closer look at longitude to see if trends in species distribution differ more drastically in regions closer to or further from the equator.


## Sources
### Dataset
"Shifting Seas: Ocean Climate & Marine Life Dataset". Kaggle, 2025. https://www.kaggle.com/datasets/atharvasoundankar/shifting-seas-ocean-climate-and-marine-life-dataset/data

### Other Research Sources

“1.5°C: What It Means and Why It Matters.” United Nations, United Nations, www.un.org/en/climatechange/science/climate-issues/degrees-matter.  Accessed 5 Dec. 2025. 

Ceccarelli, Daniela. M., et al. “Regional-Scale Disturbances Drive Long-Term Decline of Inshore Coral Reef Fish Assemblages in the Great Barrier Reef Marine Park.” Global Change Biology, 14 Oct. 2024, doi.org/10.1111/gcb.17506.  

“Global Temperature - Earth Indicator - NASA Science.” NASA, NASA, 26 Sept. 2025, science.nasa.gov/earth/explore/earth-indicators/global-temperature/.  

## Use of AI Tools
We used AI tools to help us double check code when creating data frames and to help create our code for removing influential points from the dataset.
